# -*- coding: utf-8 -*-
"""CNN_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K9iqw0QizYUPWF5msc53mCv-X6ytPDeN

ECE324 - Spotify Song Recognition Software

Part 1 : Data Collection and Information Extraction

Spotify stores audio files using the "Ogg Vorbis" file format. While this format is good for saving high quality audio files, it is not easy for us to work with. As a result, we will be using datasets comprised of .wav files
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy
import sys
import os
import pickle
import librosa
import librosa.display
from IPython.display import Audio
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow import keras

from google.colab import drive
drive.mount('/content/drive')

# CHANGE ME IF NEEDED
df = pd.read_csv("drive/My Drive/U of T/Year 3/ECE324/Data/features_3_sec.csv")
df.head()
# print(df.shape)
# print(df.dtypes)
df = df.drop(labels="filename", axis=1)
# CHANGE ME IF NEEDED
audio_recording="drive/My Drive/U of T/Year 3/ECE324/Data/genres_original/hiphop/hiphop.00001.wav"
data, sr = librosa.load(audio_recording)
#print(type(data), type(sr))
librosa.load(audio_recording, sr=45600)

import IPython
IPython.display.Audio(data, rate=sr)

"""PLOT RAW .WAV FILES"""

plt.figure(figsize=(12,4))
librosa.display.waveplot(data, color="#E67207")
plt.show()

"""PLOT SPECTROGRAMS (ONE)"""

stft = librosa.stft(data)
stft_db = librosa.amplitude_to_db(abs(stft))
plt.figure(figsize=(14,6))
librosa.display.specshow(stft, sr=sr, x_axis="time", y_axis="hz")
plt.colorbar()

"""PLOT SPECTROGRAMS (TWO)"""

stft = librosa.stft(data)
stft_db = librosa.amplitude_to_db(abs(stft))
plt.figure(figsize=(14,6))
librosa.display.specshow(stft_db, sr=sr, x_axis="time", y_axis="hz")
plt.colorbar()

"""PLOT SPECTRAL ROLLOFF"""

from sklearn.preprocessing import normalize
spectral_rolloff = librosa.feature.spectral_rolloff(data+0.01, sr=sr)[0]
plt.figure(figsize=(12,4))
librosa.display.waveplot(data, sr=sr, alpha=0.4, color="#E67207")

"""PLOT CHROMA FEATURE"""

import librosa.display as lplt
chroma = librosa.feature.chroma_stft(data, sr=sr)
plt.figure(figsize=(16,6))
lplt.specshow(chroma, sr=sr, x_axis="time", y_axis="chroma", cmap="coolwarm")
plt.colorbar()
plt.title("Chroma Features")
plt.show()

"""PLOT ZERO CROSSINGS RATE

See following source for information about how zero crossings rate can be used to classify music genres:
https://www.analyticsvidhya.com/blog/2022/01/analysis-of-zero-crossing-rates-of-different-music-genre-tracks/#:~:text=Zero%2DCrossing%20Rate%3A%20The%20zero,retrieval%20for%20classifying%20percussive%20sounds.
"""

start = 1000
end = 1200
plt.figure(figsize=(14,5))
plt.plot(data[start:end], color="#E67207")
plt.grid()

"""GET ZERO CROSSINGS COUNT

See following source for information on label encoding:
https://contactsunny.medium.com/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621

Note: Label encoding essentially turns all non-numerical data (ie. non-interpretable by computers) into data the computer can use.
"""

zero_cross_rate = librosa.zero_crossings(data[start:end], pad=False)
print("Number of zero crossings ::", sum(zero_cross_rate))

"""FEATURE EXTRACTION"""

class_list = df.iloc[:, -1]
convertor = LabelEncoder()

y = convertor.fit_transform(class_list)
# print(df.iloc[:, :-1])

from sklearn.preprocessing import StandardScaler
fit = StandardScaler()
x = fit.fit_transform(np.array(df.iloc[:, :-1], dtype=float))

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2002)
print("Size of y_train ::", len(y_train))
print("Size of y_test ::", len(y_test))

"""CNN MODEL"""

from keras.models import Sequential

def trainModel(model, epochs, optimizer):
  batch_size = 128
  model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy", metrics="accuracy")
  return model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)

def plotValidate(history):
  print("Validation Accuracy ::", max(history.history["val_accuracy"]))
  pd.DataFrame(history.history).plot(figsize=(12,6))
  plt.show()

model = keras.models.Sequential([
  keras.layers.Dense(512, activation="relu", input_shape=(x_train.shape[1],)),
  keras.layers.Dropout(0.2),

  keras.layers.Dense(256, activation="relu"),
  keras.layers.Dropout(0.2),

  keras.layers.Dense(128, activation="relu"),
  keras.layers.Dropout(0.2),

  keras.layers.Dense(64, activation="relu"),
  keras.layers.Dropout(0.2),

  keras.layers.Dense(10, activation="softmax"),                         
])
print(model.summary())
model_history = trainModel(model=model, epochs=600, optimizer="adam")

test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=128)
print("Test Loss ::", test_loss)
print("Best Test Accuracy ::", test_acc)

plotValidate(model_history)